Week 4 Report


 1. Comprehensive Model Evaluation
  - Completed training on all compressed datasets using identical CNN architecture
  - Achieved compressed model performances with 10% compression ratio:
  - Random Sampling: 83.57% (6.78% drop from baseline)
  - Stratified Sampling: 84.36% (5.99% drop from baseline) 
  - K-Center Greedy: 80.56% (9.79% drop from baseline)

 2. Detailed Performance Analysis
  - Generated comprehensive comparative visualizations:
  - Accuracy comparisons across all methods
  - Training progression and convergence curves
  - Efficiency vs compression trade-off analysis
  - Performance degradation metrics

 3. Statistical Analysis & Insights
  - Calculated key performance metrics:
  - Stratified Sampling emerged as the best compression method
  - Relative accuracy drop: 6.63% (from 90.35% to 84.36%)
  - Data efficiency: 90% reduction in training data requirements

 4. Deployment Recommendations
   - K-Center Greedy: Best for mobile deployment (minimal accuracy loss)
   - Stratified Sampling: Balanced approach for general use
   - Baseline: Maximum accuracy when resources allow